{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Required Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Time Series Analysis Background Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# The Lynx Dataset and Time Series Vectors and Lags\n",
    "# Importing the data with pandas and using its 'year' column for the index\n",
    "# Make sure that LYNXdata.csv is in the same folder as this python notebook\n",
    "mylynx_df = pd.read_csv(\"LYNXdata.csv\", header = 0,\n",
    "                     names = ['year', 'trappings'],\n",
    "                     index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the data - Note the index/ time stamp 'year'\n",
    "mylynx_df.trappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Data is still a DataFrame (pandas)\n",
    "type(mylynx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the DataFrame into a Series object\n",
    "# Reusing existing index - the new object inherits the index\n",
    "# Basically extracting the 'trappings' column from my data\n",
    "mylynxts_simple = mylynx_df['trappings']\n",
    "type(mylynxts_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mylynxts_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the DataFrame into a Series object\n",
    "# New index generation with proper date index\n",
    "mylynxts = pd.Series(mylynx_df['trappings'].values,\n",
    "                     index = pd.date_range('31/12/1821' ,\n",
    "                                           periods = 114,\n",
    "                                           freq = 'A-DEC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the new index format (d-m-Y)\n",
    "mylynxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Stationarity\n",
    "def stationarity_test(timeseries):\n",
    "    \"\"\"\"Augmented Dickey-Fuller Test\n",
    "    Test for Stationarity\"\"\"\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    df_test = adfuller(timeseries, autolag = \"AIC\")\n",
    "    df_output = pd.Series(df_test[0:4],\n",
    "                          index = [\"Test Statistic\", \"p-value\", \"#Lags Used\",\n",
    "                                   \"Number of Observations Used\"])\n",
    "    print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test application on the Lynx dataset\n",
    "stationarity_test(mylynxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test application on random normally distributed numbers\n",
    "stationarity_test(np.random.normal(1, 3, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the characteristics of stationary data on the plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(np.random.normal(1, 3, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test application on a vector of numbers\n",
    "mydata = (3, 5, 3, 65, 64, 64, 65, 643, 546, 546, 544)\n",
    "\n",
    "stationarity_test(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the three levels in the data\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Classic ACF and PACF Plots for Autocorrelation\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Autocorrelation and partical autocorrelation in the Lynx dataset\n",
    "# Two plots on one sheet\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(mylynxts, lags=20, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(mylynxts, lags=20, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Time Series in Python\n",
    "# Line graph with matplotlib pyplot module\n",
    "plt.figure(figsize=(12,8))\n",
    "mylynxts.plot()\n",
    "plt.title('Lynx Trappings in Canada 1821-1934')\n",
    "plt.xlabel('Year of Trappings')\n",
    "plt.ylabel('Number of Lynx Trapped')\n",
    "plt.legend(['Lynx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting two series on the same plot\n",
    "# Getting the cumsum of mylynxts\n",
    "# Series object, therefore the index is inherited\n",
    "cumsum_lynx = np.cumsum(mylynxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_lynx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(mylynxts)\n",
    "plt.plot(cumsum_lynx)\n",
    "plt.title('Lynx Trappings')\n",
    "plt.xlabel('Year of Trapping')\n",
    "plt.ylabel('Nr of Lynx Trapped')\n",
    "plt.legend(['Lynx per year', 'Cumilative total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting two visualizations in the same output cell\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(mylynxts)\n",
    "plt.title('Lynx Trappings')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(cumsum_lynx)\n",
    "plt.title('Cumsum of Lynx')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple moving (rolling) calculations\n",
    "# Note: the rolling methods are applicable only on pandas Series and DataFrame objects\n",
    "def plot_rolling(timeseries, window):\n",
    "    rol_mean = timeseries.rolling(window).mean()\n",
    "    rol_std = timeseries.rolling(window).std()\n",
    "    \n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    og = plt.plot(timeseries, color = \"blue\", label = \"Original\")\n",
    "    mean = plt.plot(rol_mean, color = \"red\", label = \"Rolling Mean\")\n",
    "    std = plt.plot(rol_std, color = \"black\", label = \"Rolling Std\")\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"Rolling Mean and Standard Deviation (window = \"+str(window)+\")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_rolling(mylynxts,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the smooth values only\n",
    "mylynxts.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple rolling calculation with minimum number of periods\n",
    "def plot_rolling2(timeseries, window):\n",
    "    rol_mean = timeseries.rolling(window, min_periods = 1).mean()\n",
    "    rol_std = timeseries.rolling(window, min_periods = 1).std()\n",
    "    \n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    og = plt.plot(timeseries, color = \"blue\", label = \"Original\")\n",
    "    mean = plt.plot(rol_mean, color = \"red\", label = \"Rolling Mean\")\n",
    "    std = plt.plot(rol_std, color = \"black\", label = \"Rolling Std\")\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"Rolling Mean and Standard Deviation (window = \"+str(window)+\")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# No NA values, but shorter window size\n",
    "plot_rolling2(mylynxts, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the smooth values only - minimum periods = 1\n",
    "mylynxts.rolling(30, min_periods = 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentially Weighted Moving Average\n",
    "# Note: the ewm method is applicable on pandas Series and DataFrame objects only\n",
    "def plot_ewma(timeseries, alpha):\n",
    "    expw_ma = timeseries.ewm(alpha=alpha).mean()\n",
    "\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    og_line = plt.plot(timeseries, color = \"blue\", label = \"Original\")\n",
    "    exwm_line = plt.plot(expw_ma, color = \"red\", label = \"EWMA\")\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"EWMA (alpha= \"+str(alpha)+\")\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_ewma(mylynxts, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Models in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Parameter Selection\n",
    "# Note the date format (DatetimeIndex + tuple), it is required for the ARIMA function we use below\n",
    "mylynxts = pd.Series(mylynx_df['trappings'].values,\n",
    "                 index = pd.DatetimeIndex(data = (tuple(pd.date_range('31/12/1821',\n",
    "                                                                      periods = 114,\n",
    "                                                                      freq = 'A-DEC'))),\n",
    "                                          freq = 'A-DEC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mylynxts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Test for stationarity - Parameter d\n",
    "# Applying the Augmented Dickey-Fuller test function we created in the previous section\n",
    "stationarity_test(mylynxts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for autocorrelation and partical autocorrelation - Parameters p, q\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(mylynxts, lags=20, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = plot_pacf(mylynxts, lags=20, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model Setup\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ARIMA for the model, with the argument 'order'\n",
    "# It is easy to change parameters\n",
    "model = ARIMA(mylynxts, order=(2, 0, 0))  \n",
    "results_AR = model.fit()\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(mylynxts)\n",
    "plt.plot(results_AR.fittedvalues, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Model Diagnostics\n",
    "results_AR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# ACF on Residuals of Our Model\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(results_AR.resid, lags=20, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram of the Residuals\n",
    "# Importing function for normal distribution\n",
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.hist(results_AR.resid, bins = 'auto', density = True, rwidth = 0.85,\n",
    "         label = 'Residuals') #density TRUE - norm.dist bell curve\n",
    "mu, std = norm.fit(results_AR.resid)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\n",
    "p = norm.pdf(x, mu, std) #pdf = probability density function\n",
    "plt.plot(x, p, 'm', linewidth = 2)\n",
    "plt.grid(axis='y', alpha = 0.2)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Residuals 2,0,0 vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can readjust the model as often as we like\n",
    "# Repeat the following procedure for models AR(3), AR(4) and AR(5)\n",
    "# Which one is the most promising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the Residuals: A Close Look\n",
    "# Example performed on an AR2 model\n",
    "model = ARIMA(mylynxts, order=(2, 0, 0))  \n",
    "results_AR = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last 5 observations for the original data, the fitted values and the residuals\n",
    "mylynxts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "results_AR.fittedvalues.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_AR.resid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The mean of the residuals\n",
    "np.mean(results_AR.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ACF Plot\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = plot_acf(results_AR.resid, lags=20, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram on the residuals\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.hist(results_AR.resid, bins = 'auto', density = True, rwidth = 0.85, label = 'Residuals') #density TRUE - norm.dist bell curve\n",
    "mu, std = norm.fit(results_AR.resid)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\n",
    "p = norm.pdf(x, mu, std) #pdf = probability density function\n",
    "plt.plot(x, p, 'm', linewidth = 2)\n",
    "plt.grid(axis='y', alpha = 0.2)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Residuals 2,0,0 vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# ARIMA forecasts\n",
    "# Setting up an ARIMA(4,0,0) model and storing its fitted values\n",
    "model_AR4 = ARIMA(mylynxts, order=(4, 0, 0))  \n",
    "results_AR4 = model_AR4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast based on the ARIMA(4,0,0) model\n",
    "Fcast400 = results_AR4.predict(start = '31/12/1935',\n",
    "                               end = '31/12/1945')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the comparison, let's set up another model\n",
    "# Arima(2,0,2) model and its fitted values\n",
    "model202 = ARIMA(mylynxts, order=(2, 0, 2))  \n",
    "results_M202 = model202.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast based on the ARIMA(2,0,2) model\n",
    "Fcast202 = results_M202.predict(start = '31/12/1935',\n",
    "                                end = '31/12/1945')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the forecasts via data visualization\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(mylynxts, linewidth = 2, label = \"original\")\n",
    "plt.plot(Fcast400, color='red', linewidth = 2,\n",
    "         label = \"ARIMA 4 0 0\")\n",
    "plt.plot(Fcast202, color='blue', linewidth = 2,\n",
    "         label = \"ARIMA 2 0 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models for Seasonal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'nottem' dataset as a pandas DataFrame\n",
    "# Make sure that nottem.csv is in the same folder as this python notebook\n",
    "nottem = pd.read_csv(\"nottem.csv\", header = 0, parse_dates = [0], names = ['Month', 'Temp'], index_col = 0)\n",
    "print(nottem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to a pandas Series object\n",
    "nottemts = pd.Series((nottem.Temp).values,\n",
    "                     index = pd.date_range('1920-01-31',\n",
    "                                           periods = 240,\n",
    "                                           freq = 'M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Decomposition\n",
    "# Simple seasonal decomposition\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposed = seasonal_decompose(nottemts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dplot = decomposed.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition based on stl - Package: stldecompose\n",
    "# Install the library via PIP\n",
    "# Import the decompose function\n",
    "from stldecompose import decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STL decomposition of nottem\n",
    "stl = decompose(nottemts, period=12)\n",
    "stl.trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the STL decomposition\n",
    "stlvisual = stl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Adjustment and Forecasting\n",
    "nottemadjusted = nottemts - decomposed.seasonal\n",
    "plt.figure(figsize=(12,8))\n",
    "nottemadjusted.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the seasonal component only\n",
    "plt.figure(figsize=(12,8))\n",
    "decomposed.seasonal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a forecast based on STL\n",
    "from stldecompose import forecast\n",
    "from stldecompose.forecast_funcs import (naive,\n",
    "                                         drift, \n",
    "                                         mean, \n",
    "                                         seasonal_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcast = forecast(stl, steps=12, fc_func=seasonal_naive, seasonal = True)\n",
    "\n",
    "fcast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the forecast and the original data\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(nottemts, label='data')\n",
    "plt.plot(fcast, label=fcast.columns[0])\n",
    "plt.xlim('1920','1941'); plt.ylim(30,70);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Smoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "help(ExponentialSmoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the exponential smoothing model (A,N,A)\n",
    "expsmodel = ExponentialSmoothing(nottemts, seasonal = \"additive\",\n",
    "                                 seasonal_periods = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "expsmodelfit = expsmodel.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha smoothing coefficient\n",
    "expsmodelfit.params['smoothing_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma smoothing coefficient\n",
    "expsmodelfit.params['smoothing_seasonal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with exponential smoothing\n",
    "expsfcast = expsmodelfit.predict(start = 240, end = 251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictied values and the original data\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(nottemts, label='data')\n",
    "plt.plot(expsfcast, label='HW forecast')\n",
    "plt.xlim('1920','1941'); plt.ylim(30,70);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the model to the original values\n",
    "# How good is the model fit?\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(nottemts, label='data')\n",
    "plt.plot(expsmodelfit.fittedvalues, label='HW model')\n",
    "plt.xlim('1920','1940'); plt.ylim(30,70);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Seasonal Data with Prophet by Facebook\n",
    "# Install Prophet via PIP or Conda-Forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function 'Prophet' from the library 'fbprophet'\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nottemts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas.DataFrame with the values of nottemts\n",
    "nottem_df = pd.DataFrame({'ds':nottemts.index, \n",
    "                          'y':nottemts.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nottem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prophet model and fit on the data\n",
    "mymodel = Prophet()\n",
    "mymodel.fit(nottem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a forecast with 'mymodel'\n",
    "future_data = mymodel.make_future_dataframe(periods = 12,\n",
    "                                            freq = 'm')\n",
    "\n",
    "fcast = mymodel.predict(future_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.plot(fcast)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
